{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOcm0soXmmxAoiN0E55VAa5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 3. Split the data into training and validation (70-30) \n","â¬œ â¬œ â¬œ ðŸ’£ âž¡ ðŸŽ½ + ðŸ‘Œ"],"metadata":{"id":"8tvL2NrAHhtL"}},{"cell_type":"markdown","source":["The objective is to split the annotated data into training and validation. 70-30 seems a good split"],"metadata":{"id":"vuMTnbfSLjC7"}},{"cell_type":"code","source":["annotator_ID=20 # my folder ID\n","\n","my_drive_path=\"/content/drive/MyDrive/HOME_EXAM\"\n","path_to_tiles= my_drive_path+\"/annotated_data/train/\"+str(annotator_ID)  \n","\n","# define split for training and validation\n","split_train= 0.7 # \n","split_val=1-split_train"],"metadata":{"id":"QWGc8Yu7Liyd","executionInfo":{"status":"ok","timestamp":1685610448029,"user_tz":-120,"elapsed":264,"user":{"displayName":"Jaime CANDELAS BIELZA","userId":"07463044471836979088"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["annotator_ID=\"full_data\" # change this to your folder ID\n","\n","my_drive_path=\"/content/drive/MyDrive/HOME_EXAM\"\n","path_to_tiles= my_drive_path+\"/annotated_data/train/\"+str(annotator_ID)+\"/all_data\" \n","\n","# define split for training and validation\n","split_train= 0.7 # \n","split_val=1-split_train"],"metadata":{"id":"nt7NRcmSLd0M","executionInfo":{"status":"ok","timestamp":1685610785254,"user_tz":-120,"elapsed":5,"user":{"displayName":"Jaime CANDELAS BIELZA","userId":"07463044471836979088"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## 3.1 Load libraries"],"metadata":{"id":"9nFq5Q34Mc29"}},{"cell_type":"code","source":["import os\n","import shutil\n","import random\n","\n","# mount google drive\n","# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"214t8YiUMil_","executionInfo":{"status":"ok","timestamp":1685610791618,"user_tz":-120,"elapsed":2581,"user":{"displayName":"Jaime CANDELAS BIELZA","userId":"07463044471836979088"}},"outputId":"6e9be0c9-a824-43a5-a6c7-eb94333f9179"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### 3.2 Create train and validation directories and subdivide each into \"images\" and \"labels\" sub-directories"],"metadata":{"id":"hY97A4PbMoE4"}},{"cell_type":"code","source":["train_dir = os.path.join(path_to_tiles, \"train\")\n","os.makedirs(train_dir, exist_ok=True) # creates new directory for training data\n","val_dir = os.path.join(path_to_tiles, \"val\")\n","os.makedirs(val_dir, exist_ok=True) # creates new directory for validation data\n","val_img_dir = os.path.join(path_to_tiles, \"val\",\"images\")\n","os.makedirs(val_img_dir, exist_ok=True) # creates new directory for training data\n","train_img_dir = os.path.join(path_to_tiles, \"train\",\"images\")\n","os.makedirs(train_img_dir, exist_ok=True) # creates new directory for training data\n","val_ann_dir = os.path.join(path_to_tiles, \"val\",\"labels\")\n","os.makedirs(val_ann_dir, exist_ok=True) # creates new directory for training data\n","train_ann_dir = os.path.join(path_to_tiles, \"train\",\"labels\")\n","os.makedirs(train_ann_dir, exist_ok=True) # creates new directory for training data\n"],"metadata":{"id":"8uBOyggZMmUa","executionInfo":{"status":"ok","timestamp":1685610814260,"user_tz":-120,"elapsed":17361,"user":{"displayName":"Jaime CANDELAS BIELZA","userId":"07463044471836979088"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### 3.3 Randomly sample tiles "],"metadata":{"id":"RpooLhCauWx_"}},{"cell_type":"code","source":["# Get a list of all the .txt files in the data directory\n","txt_files = [f for f in os.listdir(path_to_tiles) if f.endswith(\".txt\")]\n","img_files = [f for f in os.listdir(path_to_tiles) if f.endswith(\".tif\")]"],"metadata":{"id":"sAH2eQwTF-fQ","executionInfo":{"status":"ok","timestamp":1685610835510,"user_tz":-120,"elapsed":253,"user":{"displayName":"Jaime CANDELAS BIELZA","userId":"07463044471836979088"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# remove .txt files that have no image (not sure why ?)\n","txt_files_with_tif = []\n","for txt_file in txt_files:\n","    # get the base name of the text file\n","    txt_base_name = os.path.basename(txt_file)\n","    # replace the file extension with .tif to get the corresponding tif file name\n","    img_file = os.path.join(os.path.dirname(txt_file), os.path.splitext(txt_base_name)[0] + '.tif')\n","    img_file=path_to_tiles+\"/\"+img_file\n","    #print(\"txt: \"+txt_file)\n","    #print(\"tif: \"+img_file)\n","    # check if the tif file exists\n","    if os.path.exists(img_file):\n","      #print(\"path to image \" + img_file + \" does not exist!\")\n","      txt_files_with_tif.append(txt_file)\n","\n"],"metadata":{"id":"l6_I5DQEDd0e","executionInfo":{"status":"ok","timestamp":1685610836894,"user_tz":-120,"elapsed":1,"user":{"displayName":"Jaime CANDELAS BIELZA","userId":"07463044471836979088"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["txt_files=txt_files_with_tif\n","\n","# Shuffle the list of text files\n","random.shuffle(txt_files)\n","#train=random.sample(txt_files, ) \n","\n","# Calculate the number of files for the train and validation sets\n","train_size = int(0.7 * len(txt_files))\n","val_size = len(txt_files) - train_size"],"metadata":{"id":"2Olsju2esPOl","executionInfo":{"status":"ok","timestamp":1685610839261,"user_tz":-120,"elapsed":993,"user":{"displayName":"Jaime CANDELAS BIELZA","userId":"07463044471836979088"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### Move the text annotation files and respective images to the train and validation directories"],"metadata":{"id":"DwIl8JDcyBey"}},{"cell_type":"code","source":["# iterate through each annotated .txt file\n","for i, txt_file in enumerate(txt_files):\n","    if i < train_size:\n","        dest_dir = train_dir\n","    else:\n","        dest_dir = val_dir\n","    #print(\"path to \"+path_to_tiles+\"/\"+txt_file+\" exists: \"+ str(os.path.exists(txt_file)))\n","    if os.path.exists(path_to_tiles+\"/\"+txt_file):\n","      src_file = os.path.join(path_to_tiles, txt_file)\n","      src_img = os.path.join(path_to_tiles, os.path.splitext(txt_file)[0]+\".tif\")\n","      if os.path.exists(src_img):\n","        dest_file = os.path.join(dest_dir,\"labels\", txt_file)\n","        dest_img = os.path.join(dest_dir,\"images\", os.path.splitext(txt_file)[0]+\".tif\")\n","        #print(\"copying files\")\n","        shutil.move(src_file, dest_file)\n","        shutil.move(src_img, dest_img)"],"metadata":{"id":"6sGgm68syA51","executionInfo":{"status":"ok","timestamp":1685610843586,"user_tz":-120,"elapsed":3331,"user":{"displayName":"Jaime CANDELAS BIELZA","userId":"07463044471836979088"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## And now for the whole group's tiles"],"metadata":{"id":"rgRr5l1iOnl9"}}]}